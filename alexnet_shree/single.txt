
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Input batch shape: images: (128, 256, 256, 3) labels: (128,)
num_classes: 1000
total_num_examples: 12288
fake_data/input_producer/FIFOQueueV2
fake_data/input_producer_1/FIFOQueueV2
4 threads started for queue
2019-04-12 19:01:40.641872: step 0, loss = 8.27 (37.4 examples/sec; 3.421 sec/batch)
2019-04-12 19:01:44.027178: step 1, loss = 1.96 (44.6 examples/sec; 2.867 sec/batch)
2019-04-12 19:01:47.032641: step 2, loss = 1.96 (42.6 examples/sec; 3.003 sec/batch)
2019-04-12 19:01:50.211844: step 3, loss = 1.96 (40.3 examples/sec; 3.176 sec/batch)
2019-04-12 19:01:53.172495: step 4, loss = 1.96 (43.3 examples/sec; 2.957 sec/batch)
2019-04-12 19:01:56.098917: step 5, loss = 1.96 (43.8 examples/sec; 2.923 sec/batch)
2019-04-12 19:01:59.207494: step 6, loss = 1.96 (41.2 examples/sec; 3.105 sec/batch)
2019-04-12 19:02:02.162973: step 7, loss = 1.96 (43.4 examples/sec; 2.952 sec/batch)
2019-04-12 19:02:05.152264: step 8, loss = 1.96 (42.9 examples/sec; 2.986 sec/batch)
2019-04-12 19:02:08.259531: step 9, loss = 1.96 (41.2 examples/sec; 3.104 sec/batch)
2019-04-12 19:02:11.179867: step 10, loss = 1.96 (43.9 examples/sec; 2.917 sec/batch)
2019-04-12 19:02:14.422205: step 11, loss = 1.96 (39.5 examples/sec; 3.239 sec/batch)
2019-04-12 19:02:17.416563: step 12, loss = 1.96 (42.8 examples/sec; 2.991 sec/batch)
2019-04-12 19:02:20.456720: step 13, loss = 1.96 (42.2 examples/sec; 3.036 sec/batch)
2019-04-12 19:02:23.389654: step 14, loss = 1.96 (43.7 examples/sec; 2.930 sec/batch)
2019-04-12 19:02:26.365507: step 15, loss = 1.96 (43.1 examples/sec; 2.972 sec/batch)
2019-04-12 19:02:29.295390: step 16, loss = 1.96 (43.7 examples/sec; 2.927 sec/batch)
2019-04-12 19:02:32.334203: step 17, loss = 1.96 (42.2 examples/sec; 3.035 sec/batch)
2019-04-12 19:02:35.396259: step 18, loss = 1.96 (41.9 examples/sec; 3.058 sec/batch)
2019-04-12 19:02:38.380550: step 19, loss = 1.96 (42.9 examples/sec; 2.981 sec/batch)
2019-04-12 19:02:41.399205: step 20, loss = 1.96 (42.5 examples/sec; 3.015 sec/batch)
2019-04-12 19:02:44.405188: step 21, loss = 1.96 (42.6 examples/sec; 3.002 sec/batch)
2019-04-12 19:02:47.396294: step 22, loss = 1.96 (42.8 examples/sec; 2.987 sec/batch)
2019-04-12 19:02:50.377308: step 23, loss = 1.96 (43.0 examples/sec; 2.977 sec/batch)
2019-04-12 19:02:53.301281: step 24, loss = 1.96 (43.8 examples/sec; 2.920 sec/batch)
2019-04-12 19:02:56.314111: step 25, loss = 1.96 (42.5 examples/sec; 3.009 sec/batch)
2019-04-12 19:02:59.389959: step 26, loss = 1.96 (41.7 examples/sec; 3.072 sec/batch)
2019-04-12 19:03:02.341647: step 27, loss = 1.96 (43.4 examples/sec; 2.948 sec/batch)
2019-04-12 19:03:05.395574: step 28, loss = 1.96 (42.0 examples/sec; 3.050 sec/batch)
2019-04-12 19:03:08.325429: step 29, loss = 1.96 (43.7 examples/sec; 2.927 sec/batch)
2019-04-12 19:03:11.298217: step 30, loss = 1.96 (43.1 examples/sec; 2.970 sec/batch)
2019-04-12 19:03:14.315830: step 31, loss = 1.96 (42.5 examples/sec; 3.014 sec/batch)
2019-04-12 19:03:17.387658: step 32, loss = 1.96 (41.7 examples/sec; 3.068 sec/batch)
2019-04-12 19:03:20.365375: step 33, loss = 1.96 (43.0 examples/sec; 2.974 sec/batch)
2019-04-12 19:03:23.332502: step 34, loss = 1.96 (43.2 examples/sec; 2.964 sec/batch)
2019-04-12 19:03:26.393438: step 35, loss = 1.96 (41.9 examples/sec; 3.057 sec/batch)
2019-04-12 19:03:29.564393: step 36, loss = 1.96 (40.4 examples/sec; 3.167 sec/batch)
2019-04-12 19:03:32.620025: step 37, loss = 1.96 (41.9 examples/sec; 3.052 sec/batch)
2019-04-12 19:03:35.597333: step 38, loss = 1.96 (43.0 examples/sec; 2.974 sec/batch)
2019-04-12 19:03:38.635504: step 39, loss = 1.96 (42.2 examples/sec; 3.036 sec/batch)
2019-04-12 19:03:41.587805: step 40, loss = 1.96 (43.4 examples/sec; 2.950 sec/batch)
2019-04-12 19:03:44.545963: step 41, loss = 1.96 (43.3 examples/sec; 2.955 sec/batch)
2019-04-12 19:03:47.634734: step 42, loss = 1.96 (41.5 examples/sec; 3.085 sec/batch)
2019-04-12 19:03:50.578488: step 43, loss = 1.96 (43.5 examples/sec; 2.940 sec/batch)
2019-04-12 19:03:53.680449: step 44, loss = 1.95 (41.3 examples/sec; 3.098 sec/batch)
2019-04-12 19:03:56.594736: step 45, loss = 1.95 (44.0 examples/sec; 2.911 sec/batch)
2019-04-12 19:03:59.647776: step 46, loss = 1.95 (42.0 examples/sec; 3.049 sec/batch)
2019-04-12 19:04:02.563208: step 47, loss = 1.95 (44.0 examples/sec; 2.912 sec/batch)
2019-04-12 19:04:05.568885: step 48, loss = 1.95 (42.6 examples/sec; 3.002 sec/batch)
2019-04-12 19:04:08.526469: step 49, loss = 1.95 (43.3 examples/sec; 2.954 sec/batch)
2019-04-12 19:04:11.565331: step 50, loss = 1.95 (42.2 examples/sec; 3.035 sec/batch)
2019-04-12 19:04:14.596478: step 51, loss = 1.95 (42.3 examples/sec; 3.029 sec/batch)
2019-04-12 19:04:17.574231: step 52, loss = 1.95 (43.0 examples/sec; 2.974 sec/batch)
2019-04-12 19:04:20.513332: step 53, loss = 1.95 (43.6 examples/sec; 2.935 sec/batch)
2019-04-12 19:04:23.506248: step 54, loss = 1.95 (42.8 examples/sec; 2.989 sec/batch)
2019-04-12 19:04:26.522520: step 55, loss = 1.95 (42.5 examples/sec; 3.014 sec/batch)
2019-04-12 19:04:29.544806: step 56, loss = 1.95 (42.4 examples/sec; 3.019 sec/batch)
2019-04-12 19:04:32.497826: step 57, loss = 1.95 (43.4 examples/sec; 2.949 sec/batch)
2019-04-12 19:04:35.436471: step 58, loss = 1.95 (43.6 examples/sec; 2.936 sec/batch)
2019-04-12 19:04:38.360829: step 59, loss = 1.95 (43.8 examples/sec; 2.921 sec/batch)
2019-04-12 19:04:41.509235: step 60, loss = 1.95 (40.7 examples/sec; 3.146 sec/batch)
2019-04-12 19:04:44.408142: step 61, loss = 1.95 (44.2 examples/sec; 2.895 sec/batch)
2019-04-12 19:04:47.502642: step 62, loss = 1.95 (41.4 examples/sec; 3.091 sec/batch)
2019-04-12 19:04:50.447500: step 63, loss = 1.95 (43.5 examples/sec; 2.941 sec/batch)
2019-04-12 19:04:53.620607: step 64, loss = 1.95 (40.4 examples/sec; 3.169 sec/batch)
2019-04-12 19:04:56.591022: step 65, loss = 1.95 (43.1 examples/sec; 2.967 sec/batch)
2019-04-12 19:04:59.652106: step 66, loss = 1.95 (41.9 examples/sec; 3.058 sec/batch)
2019-04-12 19:05:02.613778: step 67, loss = 1.95 (43.3 examples/sec; 2.958 sec/batch)
2019-04-12 19:05:05.758688: step 68, loss = 1.95 (40.7 examples/sec; 3.143 sec/batch)
2019-04-12 19:05:08.678620: step 69, loss = 1.95 (43.9 examples/sec; 2.916 sec/batch)
2019-04-12 19:05:11.636656: step 70, loss = 1.95 (43.3 examples/sec; 2.954 sec/batch)
2019-04-12 19:05:14.626954: step 71, loss = 1.95 (42.9 examples/sec; 2.985 sec/batch)
2019-04-12 19:05:17.520877: step 72, loss = 1.95 (44.3 examples/sec; 2.890 sec/batch)
2019-04-12 19:05:20.504173: step 73, loss = 1.95 (43.0 examples/sec; 2.980 sec/batch)
2019-04-12 19:05:23.436713: step 74, loss = 1.95 (43.7 examples/sec; 2.929 sec/batch)
2019-04-12 19:05:26.306653: step 75, loss = 1.95 (44.6 examples/sec; 2.868 sec/batch)
2019-04-12 19:05:29.293664: step 76, loss = 1.95 (42.9 examples/sec; 2.983 sec/batch)
2019-04-12 19:05:32.187227: step 77, loss = 1.95 (44.3 examples/sec; 2.890 sec/batch)
2019-04-12 19:05:35.166118: step 78, loss = 1.95 (43.0 examples/sec; 2.977 sec/batch)
2019-04-12 19:05:38.263926: step 79, loss = 1.95 (41.4 examples/sec; 3.094 sec/batch)
2019-04-12 19:05:41.099260: step 80, loss = 1.95 (45.2 examples/sec; 2.832 sec/batch)
2019-04-12 19:05:44.339861: step 81, loss = 1.95 (39.5 examples/sec; 3.237 sec/batch)
2019-04-12 19:05:47.374356: step 82, loss = 1.95 (42.2 examples/sec; 3.031 sec/batch)
2019-04-12 19:05:50.379826: step 83, loss = 1.95 (42.6 examples/sec; 3.002 sec/batch)
2019-04-12 19:05:53.314586: step 84, loss = 1.95 (43.7 examples/sec; 2.931 sec/batch)
2019-04-12 19:05:56.349372: step 85, loss = 1.95 (42.2 examples/sec; 3.031 sec/batch)
2019-04-12 19:05:59.203934: step 86, loss = 1.95 (44.9 examples/sec; 2.852 sec/batch)
2019-04-12 19:06:02.305342: step 87, loss = 1.95 (41.3 examples/sec; 3.098 sec/batch)
2019-04-12 19:06:05.203187: step 88, loss = 1.95 (44.2 examples/sec; 2.895 sec/batch)
2019-04-12 19:06:08.352544: step 89, loss = 1.95 (40.7 examples/sec; 3.146 sec/batch)
2019-04-12 19:06:11.253455: step 90, loss = 1.95 (44.2 examples/sec; 2.897 sec/batch)
2019-04-12 19:06:14.342891: step 91, loss = 1.95 (41.5 examples/sec; 3.087 sec/batch)
2019-04-12 19:06:17.199282: step 92, loss = 1.95 (44.9 examples/sec; 2.854 sec/batch)
2019-04-12 19:06:20.152908: step 93, loss = 1.95 (43.4 examples/sec; 2.951 sec/batch)
2019-04-12 19:06:23.140494: step 94, loss = 1.95 (42.9 examples/sec; 2.985 sec/batch)
2019-04-12 19:06:26.107087: step 95, loss = 1.95 (43.2 examples/sec; 2.963 sec/batch)
Average 42.7 examples/sec
